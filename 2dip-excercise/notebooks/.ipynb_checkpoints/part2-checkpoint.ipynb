{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "```\n",
    "2DIP_exercise/\n",
    "│-- data/             # Contains images & videos\n",
    "│   │-- input/        # 1 image and 1 video for each phase respectively\n",
    "│   │-- output/       # All output images/videos must be stored here\n",
    "│-- notebooks/        # Jupyter Notebooks for each phase\n",
    "│   │-- part1.ipynb   # Image processing & feature extraction\n",
    "│   │-- part2.ipynb   # Optical flow, object detection and tracking \n",
    "│-- README.md         # Project instructions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define paths\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "inputs = os.path.join(base_path, 'data','input')\n",
    "outputs = os.path.join(base_path, 'data','output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplementary Code for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(image):\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(video_path):\n",
    "    # Re-open the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Convert BGR to RGB for matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame_rgb)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['animation.embed_limit'] = 100\n",
    "\n",
    "def display_video(video_path):\n",
    "    \n",
    "    frames = get_frames(video_path)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "    im = ax.imshow(np.zeros_like(frames[0]))\n",
    "    ax.axis('off')\n",
    "\n",
    "    def update(frame):\n",
    "        im.set_array(frame)\n",
    "        return [im]\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=frames, interval=50, blit=True, repeat=False)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Analyze movement patterns in a video sequence. **(6)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Compute dense optical flow for each frame in a video of a moving crowd. **(2)**\n",
    "\n",
    "b) Visualize the movement patterns in 2 different ways. **(2+2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_flow(video_path, output_path1, output_path2):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(inputs, 'part2.mp4')  # Replace with your input video path\n",
    "output_path1 = os.path.join(outputs, 'optical_flow_1.mp4')  # Output visualization video path\n",
    "output_path2 = os.path.join(outputs, 'optical_flow_2.mp4')  # Output visualization video path\n",
    "\n",
    "optical_flow(video_path, output_path1, output_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = display_video(output_path1)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = display_video(output_path2)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Identify and track a moving object in a video sequence. **(9)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Detect an object using template matching. The output would be the first frame where it appears, with a bounding box around the detected object. **(2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_object(video_path, template_path, output_path):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(inputs, 'part2.mp4')  # Replace with your input video path\n",
    "template_path = os.path.join(inputs, 'template.png')  # Replace with your template image path\n",
    "output_path = os.path.join(outputs, 'detected_object.jpg')  # Output video path\n",
    "\n",
    "image = locate_object(video_path, template_path, output_path)\n",
    "display_images(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Implement a Kalman filter to predict the object's position in subsequent frames. **(5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track(video_path, template_path, output_path):\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(inputs, 'part2.mp4')  # Replace with your input video path\n",
    "template_path = os.path.join(inputs, 'template.png')  # Replace with your template image path\n",
    "output_path = os.path.join(outputs, 'tracked_object.mp4')  # Output video path\n",
    "\n",
    "track(video_path, template_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = display_video(output_path)\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Compare Bayesian filtering and Kalman filtering (theoretically). **(2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO c):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
